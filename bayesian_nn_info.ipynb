{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e84121-88a9-4987-83bc-49d08b5e1985",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22113f-e267-4530-8929-1e5e8b2cde7e",
   "metadata": {},
   "source": [
    "## Useful literature\n",
    "* [Financial forecasting with probabilistic programming and pyro (Medium)](https://alexrachnog.medium.com/financial-forecasting-with-probabilistic-programming-and-pyro-db68ab1a1dba)\n",
    "    * Author has several tutorials for financial forecasting with neural nets\n",
    "* [Bayesian time series forecasting (Medium)](https://medium.com/geekculture/bayesian-time-series-forecasting-c8e1928d34d4)\n",
    "* (Hands-on Bayesian for deep learning (Youtube))[https://www.youtube.com/watch?v=T5TPaI5H4q8]\n",
    "* https://www.coursera.org/learn/probabilistic-deep-learning-with-tensorflow2\n",
    "* https://www.coursera.org/lecture/probabilistic-deep-learning-with-tensorflow2/probabilistic-layers-xBWQh\n",
    "* [What uncertainties tell you in bayesian NNs (Towardsdatascience)](https://towardsdatascience.com/what-uncertainties-tell-you-in-bayesian-neural-networks-6fbd5f85648e)\n",
    "\n",
    "### Relevant libraries\n",
    "* Tensorflow Probability\n",
    "* Tensorflow BNN\n",
    "* Pytorch\n",
    "* Pyro (builds on Pytorch)\n",
    "* Edward\n",
    "* PyMC3\n",
    "* InferPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ccf98-4f29-459e-805d-4a1b91598916",
   "metadata": {},
   "source": [
    "## [1] Introduction to Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c721809-4329-42eb-b054-7483670df434",
   "metadata": {},
   "source": [
    "#### Contents:\n",
    "1. Motivation\n",
    "2. Uncertainty quantification<br>\n",
    "    2.1 Aleatoric and epistemic uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1e872-59ca-43fb-9e9d-f3b2bcdadd5e",
   "metadata": {},
   "source": [
    "### [1.1] Motivation\n",
    "* Quantify the uncertainty of a model's predictions for more sound decision making\n",
    "* Better at avoiding overfitting which is a common problem with regular NNs\n",
    "* Explainability\n",
    "* Allows separation of aleatoric and epistemic uncertainty\n",
    "* Much noise in financial time series makes regular NNs more prone to overfitting, e.g., finding spurious trends in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97315de-cc21-41c3-becd-0707d4e559bd",
   "metadata": {},
   "source": [
    "### [1.2] Uncertainty quantification\n",
    "Model (epistemic) vs data uncertainty (aleatoric):\n",
    "* Aleatoric: Inherent uncertainty in data, i.e., statistical uncertainty -- irreducable\n",
    "* Epistemic: Knowledge uncertainty\n",
    "\n",
    "Predictive uncertainty is the sum of the aleatoric and epistemic uncertainty, where the latter can be viewed as a distribution over the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cab926-4ab3-44dd-9628-b376e8a55fb0",
   "metadata": {},
   "source": [
    "## [2] Bayesian Neural Nets\n",
    "\n",
    "### Note about priors and posterior\n",
    "<b>Priors</b> are the initial distribution of the parameters, e.g., the network weights: $P(w)$<br> \n",
    "<b>Posteriors</b> are the distribution of the parameters given the evidence/data; $P(w|D)$\n",
    "___\n",
    "General Bayesian:\n",
    "$ P(H|D) = \\frac{P(D|H)P(H)}{P(D)} = \\frac{P(D,H)}{\\int_{H}P(D,H^{'})dH^{'}} $ <br>\n",
    "Notations:\n",
    "* H: Hypothesis (network weights)\n",
    "* D: Evidence/Data \n",
    "\n",
    "Predictions:\n",
    "* Marginal probability distribution $P(y|x, D)$ (cond. probability of labels given data inputs <b>x</b> and training data <b>D</b>) quantifies model's uncertainty on prediction\n",
    "* Using a Monte Carlo approach, the final prediction can be obtained by sampling and averaging the marginal prediction distribution\n",
    "\n",
    "Problems:\n",
    "* Need for prior belief for weights, i.e., $P(H)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb56cbb-60db-43a3-90ec-6216a366708a",
   "metadata": {},
   "source": [
    "### [2.1] Stochastic Neural Nets\n",
    "___\n",
    "<b> Stochastic neural nets as ensemble models </b>\n",
    "\n",
    "Introducing randomness into neural net can be done in two ways:\n",
    "* Stochastic activation function\n",
    "* Stochastic weights<br>\n",
    "\n",
    "This achieves a network capable of simulating multiple different models $\\theta$ with probability distribution $p(\\theta)$. Thus, they can be considered as a special case of ensemble learning.\n",
    "<br>\n",
    "By comparing predictions from multiple different models it is possible to obtain a measure of uncertainty. If different models agree on the results, the uncertainty is low, and high if they disagree.\n",
    "___\n",
    "<b> Predictions </b>\n",
    "\n",
    "The marginal distribution of a prediction, $p(y|x,D)$, quantifies the uncertainty on given predictions. The posterior distribution of the model parameters, $p(\\theta|D)$, allows for computing the marginal prediction as $$p(y|x,D) = \\int_{\\theta}p(y|x,\\theta^{'}p(\\theta^{'}|D)d\\theta^{'}$$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca320f7b-5cb8-4021-9667-bd9d80743e09",
   "metadata": {},
   "source": [
    "<b>Setting priors</b>\n",
    "1. Normal prior with zero mean and diagonal covariance $\\sigma I$<br>\n",
    "    * Good default prior due to mathematical properties of normal distribution, but no theoretical foundation for its use.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac80cac-ae5d-48d2-ab7a-8855d8d6429d",
   "metadata": {},
   "source": [
    "## [3] Algorithms\n",
    "\n",
    "The posterior probability $P(H|D)$ is often intractable due to the integral $\\int_{H}P(D|H^{'})P(H^{'})dH^{'}$. Thus, approximations and sampling methods are used to learn the posterior, where two main methods are most prevalent: <i>Monte Carlo methods</i> and <i>Variational Inference</i>.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43995a-b84b-4bf0-8af1-cc94e5d89ee4",
   "metadata": {},
   "source": [
    "### [3.1] Monte Carlo\n",
    "Key points:\n",
    "* Generate i.i.d samples from distribution to estimate expected value/average\n",
    "* Law of large numbers, given i.i.d. samples and bounded variance => converges to expected value \n",
    "* Central limit theorem: for sufficiently large samples, estimated average converges to normal distribution\n",
    "\n",
    "Further methods\n",
    "* Explain and demonstrate dropout within a Monte Carlo framework\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d27e3d-b54c-41f7-acd0-7ad2efef4078",
   "metadata": {},
   "source": [
    "<b>Method</b>\n",
    "\n",
    "Monte Carlo methods tries to sample the posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e2b2-4859-4158-b1da-eeca9adb8ac7",
   "metadata": {},
   "source": [
    "### [3.2] Monte Carlo Markov Chain (MCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e142a-75ac-4ff1-9525-f6cf7331854d",
   "metadata": {},
   "source": [
    "<b>Method and drawbacks</b>\n",
    "\n",
    "MCMC methods tries to sample the exact posterior distribution by constructing a Markov chain. This is achieved by drawing random samples which depends solely on the previously drawn sample, thus aquiring a desired distribution.\n",
    "\n",
    "There are some issues with these methods:\n",
    "* There is often the need for an initial burn-in time before the chain converges to the desired distribution. \n",
    "* Autocorrelation between samples may be present, thus demanding a large number of samples to approximate independent sampling.\n",
    "* The drawn samples has to be stored after training, which is expensive for most deep learning models.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014d59e-ab20-4594-93ad-2978ad0897ca",
   "metadata": {},
   "source": [
    "<b>Metropolis-Hasting algortihm</b>\n",
    "\n",
    "The algorithm starts with an initial guess $\\theta$. Then, a second sample is drawn based on a proposed distribution $Q(\\theta^{'}|\\theta)$. Depending on the target distribution, the sample is either accepted or rejected. If it is rejected, a new sample is constructed. Otherwise, the algorithm continues with $\\theta^{'}$ as the new benchmark for the desired number of steps.\n",
    "The acceptance probability is computed as \n",
    "$$p=\\min{\\left(1, \\frac{Q(\\theta^{'}|\\theta_{n})}{Q(\\theta_{n}|\\theta^{'})}\\frac{f(\\theta^{'})}{f(\\theta_n)}\\right)}$$\n",
    "If $Q$ is chosen to be symmetric, the acceptance formula is easier to compute and the algorithm is only called the <i>Metropolis method</i>. Examples include normal and uniform distributions.\n",
    "In the case of bounded domains, a non-symmetric distribution must be utilized.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e5bd6-395d-4d57-afb2-fd2ce3c1b57a",
   "metadata": {},
   "source": [
    "<b>Hamiltonian Monte Carlo algorithm</b> \n",
    "\n",
    "This method builds upon the Metropolis method such that it tries to draw as few samples of $\\theta_{'}$ as possible, and additionally attempts to avoid correlations between samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ecb11-b1e3-4350-92b3-2fe83863e901",
   "metadata": {},
   "source": [
    "### [3.3] Variational Inference\n",
    "Key points:\n",
    "* Approximate inference\n",
    "* Uses Kullback-Leibler divergence to provide evidence lower bound; compute a lower bound of the likelihood\n",
    "    * Converts into optimization problem\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b53f49-f23f-40d6-b35b-d0a932aecc13",
   "metadata": {},
   "source": [
    "<b>Method and drawbacks</b>\n",
    "\n",
    "Variational inference approximates the posterior by optimization. A variational distribution $q_{\\phi}(H)$ paremeterized by $\\phi$ is chosen. Then, the parameters is learned to get the distribution as close as possible to the exact posterior. The measure of closeness if often done by the Kullback-Leibler divergence. As the exact KL-divergence requires computing the posterior, the   evidence lower bound (ELBO) is used as the loss for the approximation. \n",
    "\n",
    "A popular method for optimization is <i>Stochastic Variational Inference</i> (SVI); the stochastic gradient descent algorithm applied to variational inference.\n",
    "\n",
    "Typical distributions for $q_{\\phi}(H)$ are constructed from the exponential family of distributions, e.g., multivariate normal, Gamma and Dirichlet.\n",
    "\n",
    "One problem with this method concerns deep learning, where the stochasticity stops backpropagation from functioning within the internal nodes of the network.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f3ecb-e426-4137-bf48-792daa6b097a",
   "metadata": {},
   "source": [
    "<b>Bayes-by-backprop</b>\n",
    "\n",
    "This method is a practical implementation of SVI, where the problems surrounding backpropagation is overcome by a reparametrization trick. The general idea is to use a random variable $\\epsilon$ in the transformation $\\theta=t(\\epsilon,\\phi)$ to obtain the parameters. This allows backpropagation to work as usual for the variational parameters $\\phi$. \n",
    "\n",
    "As the objective function is a single sample of the ELBO, it will be noisy. As a countermeasure, the loss could be averaged over multiple epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9142a-8aec-4a43-99c3-b4abbe38882c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-venv",
   "language": "python",
   "name": "master-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
