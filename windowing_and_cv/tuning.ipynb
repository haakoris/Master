{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/rykc7t6j5rq5c3w33l4blqj00000gn/T/ipykernel_34048/2960739965.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "from window_generator import WindowGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kerastuner as kt\n",
    "from fredapi import Fred\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import math\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import tensorflow as tf\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>25.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>25.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>25.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "2003-01-02  25.39\n",
       "2003-01-03  24.68\n",
       "2003-01-06  24.91\n",
       "2003-01-07  25.13\n",
       "2003-01-08  25.53"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = \"2003-01-02\" \n",
    "end_date = \"2022-12-30\"\n",
    "\n",
    "FRED_API_KEY = \"29b81578246f3b1d8661dfdb956124ba\"\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "vix = fred.get_series(\"VIXCLS\", observation_start=start_date, observation_end=end_date).to_frame()\n",
    "vix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>25.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>25.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>25.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>21.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>22.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>21.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>21.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5217 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VIX\n",
       "2003-01-02  25.39\n",
       "2003-01-03  24.68\n",
       "2003-01-06  24.91\n",
       "2003-01-07  25.13\n",
       "2003-01-08  25.53\n",
       "...           ...\n",
       "2022-12-26    NaN\n",
       "2022-12-27  21.65\n",
       "2022-12-28  22.14\n",
       "2022-12-29  21.44\n",
       "2022-12-30  21.67\n",
       "\n",
       "[5217 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix.rename(columns={0:\"VIX\"}, inplace=True)\n",
    "vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(vix.columns)}\n",
    "n = len(vix)\n",
    "n_train = int(n*0.7)\n",
    "n_val = int(n*0.9)\n",
    "train_df = vix[0:n_train]\n",
    "val_df = vix[n_train:n_val]\n",
    "test_df = vix[n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "input_width = 30\n",
    "\n",
    "w = WindowGenerator(input_width=input_width, \n",
    "                    label_width=1,\n",
    "                    shift=1,\n",
    "                    train_df=train_df,\n",
    "                    val_df=val_df,\n",
    "                    test_df=test_df,\n",
    "                    n_splits=5,\n",
    "                    train_splits=3,\n",
    "                    test_splits=1, \n",
    "                    scaler=MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as backend\n",
    "\n",
    "def qlike(y_true, y_pred):\n",
    "  return tf.math.log(y_pred) + (y_true / y_pred)\n",
    "\n",
    "def build_model(hp):\n",
    "    backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('input_unit', min_value=32, max_value=256, step=32), return_sequences=True, input_shape=(input_width, 1))) #(timesteps, features)\n",
    "    for i in range(hp.Int('n_layers', 1, 2)):\n",
    "        model.add(LSTM(hp.Int(f'lstm_{i}_units', min_value=32, max_value=256, step=32), return_sequences=True))\n",
    "    model.add(LSTM(hp.Int('layer_2_neurons', min_value=32, max_value=64, step=32)))\n",
    "    model.add(Dropout(hp.Float('Dropout_rate', min_value=0.1, max_value=0.3, step=0.1)))\n",
    "    model.add(Dense(1, activation=\"relu\"))\n",
    "    #model.add(Dense(1, activation=hp.Choice('dense_activation', values=['relu'], default='relu')))\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    metrics = [\"mse\", \"mae\", \"mape\", tf.keras.metrics.RootMeanSquaredError(), qlike]\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate), metrics = metrics)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bayesian Optimization for hyperparameter search](https://arxiv.org/pdf/1806.10282.pdf)\n",
    "\n",
    "[Keras tuner oracles](https://keras.io/api/keras_tuner/oracles/)\n",
    "\n",
    "[Keras tuner API](https://keras.io/api/keras_tuner/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVTuner(kt.engine.tuner.Tuner):\n",
    "    def run_trial(self, trial, window, *args, **kwargs):\n",
    "        val_mse_list = []\n",
    "        ###\n",
    "        #batch_size = trial.hyperparameters.Int('batch_size', 8, 64, step=8)\n",
    "        #epochs = trial.hyperparameters.Int('epochs', 10, 100, step=10)\n",
    "\n",
    "        folds = window.np_folds\n",
    "        for x_train, y_train, x_test, y_test in folds:\n",
    "          model = self.hypermodel.build(trial.hyperparameters)\n",
    "          model.fit(x_train, y_train, batch_size=32, epochs=50, validation_data=(x_test, y_test), verbose=0)\n",
    "          val_loss, val_mse, val_mae, val_mape, val_rmse, val_qlike = model.evaluate(x_test, y_test)\n",
    "          val_mse_list.append(val_loss)\n",
    "          #self.save_model(trial.trial_id, model)\n",
    "          del model\n",
    "        del folds\n",
    "        \n",
    "        self.oracle.update_trial(trial.trial_id, {'val_mse': np.mean(val_mse_list),\n",
    "                                                    'val_mse_std': np.std(val_mse_list)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 08m 01s]\n",
      "val_mse: 0.010438436164986343\n",
      "\n",
      "Best val_mse So Far: 0.006338864093413577\n",
      "Total elapsed time: 00h 42m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = CVTuner(oracle=kt.oracles.BayesianOptimizationOracle(objective='val_mse', max_trials=100), hypermodel=build_model, directory=\"baseline\", project_name=\"lstm\", overwrite=False)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)\n",
    "\n",
    "tuner.search(window=w, callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_unit': 32,\n",
       " 'n_layers': 1,\n",
       " 'lstm_0_units': 160,\n",
       " 'layer_2_neurons': 64,\n",
       " 'Dropout_rate': 0.2,\n",
       " 'learning_rate': 0.001,\n",
       " 'lstm_1_units': 192}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
